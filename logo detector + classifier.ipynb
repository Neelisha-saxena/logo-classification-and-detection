{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall findings about data:\n",
    "#### Total 27 logos in data\n",
    "#### 809 Training images and 270 testing images out of which only 135 are labeled\n",
    "#### training set has 30 images per class but one image is missing\n",
    "#### test set has 5 images per class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Localizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### subset column is dropped since it is of no use for the predictions\n",
    "#### also dropping the duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_table('flickr_logos_27_dataset_training_set_annotation.txt',sep=' ',names=['filename','logo' ,'subset', 'x1','y1','x2','y2'],index_col=False)\n",
    "data = data.drop('subset',axis=1)\n",
    "data = data.drop_duplicates(subset=['filename','logo','x1','y1','x2','y2'], keep='first')\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data is splitted into 6 arrays...X_train, y_train, X_valid, y_valid, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=(224,224)\n",
    "def process_image(img_file):\n",
    "    img=cv2.imread(img_file) \n",
    "    img = cv2.cvtColor( img, cv2.COLOR_BGR2RGB ) \n",
    "    img=cv2.resize(img,size) # resizing all into a common size\n",
    "    img = img - img.mean() #centering\n",
    "    img = img/255 #normalisation\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "for i in range(data.shape[0]):\n",
    "    X.append( process_image( 'flickr_logos_27_dataset_images/'+ data['filename'][i] ))\n",
    "X = np.array(X)\n",
    "y = data[['x1','y1','x2','y2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approaching the problem as the standard way, not the way to just solve problem.\n",
    "#### Hence, using a seperate validation set also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X ,y )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we have less data as needed to train a deep neural network, so we perform data augmentation\n",
    "### but data augmentation will not help here much as data is consisting of coordinates, so we can't move objects hence only normalisation and whitening can be applied...hence applying data augmentation to this much only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# data generator\n",
    "def create_datagen():\n",
    "    datagen = ImageDataGenerator(\n",
    "    featurewise_center=True, # Set input mean to 0 over the dataset, feature-wise\n",
    "    featurewise_std_normalization=True, # Divide inputs by std of the dataset, feature-wise\n",
    "    zca_whitening=True, # Apply ZCA whitening\n",
    "    rotation_range=0, # Degree range for random rotations\n",
    "    width_shift_range=0, # Range for random horizontal shifts\n",
    "    height_shift_range=0, # Range for random vertical shifts\n",
    "    shear_range=0, # hear Intensity (Shear angle in counter-clockwise direction as radians)\n",
    "    zoom_range=0, # Range for random zoom. If a float\n",
    "    channel_shift_range=0, # Range for random channel shifts\n",
    "    fill_mode='nearest', # Points outside the boundaries of the input are filled according to the given mode\n",
    "    horizontal_flip=False, # Randomly flip inputs horizontally\n",
    "    vertical_flip=False, # Randomly flip inputs vertically\n",
    "  )\n",
    "    return datagen\n",
    "# instantiate a data generator\n",
    "datagen = create_datagen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.models import model_from_json\n",
    "from sklearn.metrics import log_loss\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization, regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating a regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Although for object localisation, we can use state-of-the-art pretrained models for the task like YOLO, Faster R-CNN, or the google one SSD (single shot detector)\n",
    "##### facebook has also recently launched such a model)\n",
    "### But I can't find some official implementation of these models in keras documentation. So instead of going for the models what people have created and open-source it, I have choosen to create my own model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createmodel():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(16, (3, 3) , border_mode='same', init='he_normal', \n",
    "                            input_shape=(3,224,224))  )\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "\n",
    "    model.add(Convolution2D(64, ( 3, 3), border_mode='same', init='he_normal',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "\n",
    "    model.add(Convolution2D(64, (3, 3), border_mode='same', init='he_normal'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Convolution2D(64, (3, 3), border_mode='same', init='he_normal'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Convolution2D(64, (3, 3), border_mode='same', init='he_normal'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4))\n",
    "    \n",
    "    model.add(Activation('linear')) #as opposed to classification, regression task will not have softmax as activation for last layer\n",
    "\n",
    "    model.compile(Adam(lr=1e-4), loss='mean_squared_error',metrics=['mean_squared_error'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logo_localizer = createmodel()\n",
    "hist = logo_localizer.fit_generator( datagen.flow( X_train, y_train), samples_per_epoch=len(X_train) * 2, epochs=50,\n",
    "                            validation_data=(X_valid,y_valid)) #augmenting data by a factor of 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,3))\n",
    "plt.title('Optimizer : Adam', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.plot(hist.history['loss'], 'b', label='Training Loss')\n",
    "plt.plot(hist.history['val_loss'], 'r', label='Validation Loss')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "model_json=logo_localizer.to_json()\n",
    "with open(\"logo_localizer.json\",'w')as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "logo_localizer.save_weights(\"logo_localizer.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_table('flickr_logos_27_dataset_query_set_annotation.txt',sep='\\t',names=['filename','logo'], na_values='none',index_col=False)\n",
    "test_data.dropna(inplace=True)\n",
    "test_data.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = []\n",
    "for i in range(test_data.shape[0]):\n",
    "    X_test.append(process_image( 'flickr_logos_27_dataset_images/'+test_data['filename'][i] ))\n",
    "X_test = np.array(X_test)\n",
    "y_pred = logo_localizer.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hence, y_pred will contain all the predicted bounding box coordinates as vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### setting coordinates in image range, i.e., 0 <= coordinates <= 224 ...............simply threshloding worked for me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#setting coordinates in image range, i.e., 0 <= coordinates <= 224\n",
    "#simply threshloding worked for me\n",
    "for i in range(y_pred.shape[0]):\n",
    "    for j in range(y_pred.shape[1]):\n",
    "        if(y_pred[i][j]<0):\n",
    "            y_pred[i][j] = 0\n",
    "        if(y_pred[i][j]>224):\n",
    "            y_pred[i][j]= 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hence y_pred has predicted coordinates for all testing classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, crop the images of training set based on the coordinates of logo...hence improving training set for classifier model\n",
    "#### for testing , we first find coordinates of logo using logo_localizer model and then crop the testing images for prediction on classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier model (using localizer model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crop_data = pd.read_table('flickr_logos_27_dataset_training_set_annotation.txt',sep=' ',names=['filename','logo' ,'subset', 'x1','y1','x2','y2'],index_col=False)\n",
    "crop_data = crop_data.drop('subset',axis=1)\n",
    "crop_data = crop_data.drop_duplicates(subset=['filename','logo','x1','y1','x2','y2'], keep='first')\n",
    "crop_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### crop_data is splitted into 6 arrays...cx_train, cy_train, cx_valid, cy_valid, cx_test, cy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size=(64,64)\n",
    "def load_crop(img_file,x1,y1,x2,y2):\n",
    "    img=cv2.imread(img_file)\n",
    "    img = cv2.cvtColor( img, cv2.COLOR_BGR2RGB )\n",
    "    if(not (x1==x2 and y1==y2)):\n",
    "        img = img[y1:y2, x1:x2]\n",
    "    img=cv2.resize(img,size) # resizing all into a common size, as there are many different image sizes\n",
    "    img = img - img.mean()\n",
    "    img = img/255\n",
    "    return img #returning reduced image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cx = []\n",
    "for i in range(crop_data.shape[0]):\n",
    "    cx.append(load_crop( 'flickr_logos_27_dataset_images/'+crop_data['filename'][i] , crop_data.x1[i],crop_data.y1[i],crop_data.x2[i],crop_data.y2[i]))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example of some corrupt values of dataset, i.e. , coordinates are invalid for a bouding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2662264721.jpg', 'RedBull', 3, 197, 3, 197], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_data.values[893]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crop_imgs = np.array(crop_imgs)\n",
    "crop_labels = data['logo']\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "crop_labels  = le.fit_transform(crop_labels) # as keras one hot endoing works only for integers\n",
    "\n",
    "from keras.utils import np_utils\n",
    "crop_labels = np_utils.to_categorical(crop_labels,27)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "cx_train, cx_valid, cy_train, cy_valid = train_test_split(crop_imgs, crop_labels , stratify = crop_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## here also data augmentation is limited as only logos are present in the image, so we can't shift but can rotate or flip( including previous things)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# data generator\n",
    "def crop_datagen():\n",
    "    datagen = ImageDataGenerator(\n",
    "    featurewise_center=True, # Set input mean to 0 over the dataset, feature-wise\n",
    "    featurewise_std_normalization=True, # Divide inputs by std of the dataset, feature-wise\n",
    "    zca_whitening=True, # Apply ZCA whitening\n",
    "    rotation_range=30, # Degree range for random rotations\n",
    "    width_shift_range=0, # Range for random horizontal shifts\n",
    "    height_shift_range=0, # Range for random vertical shifts\n",
    "    shear_range=0, # hear Intensity (Shear angle in counter-clockwise direction as radians)\n",
    "    zoom_range=0, # Range for random zoom. If a float\n",
    "    channel_shift_range=0.2, # Range for random channel shifts\n",
    "    fill_mode='nearest', # Points outside the boundaries of the input are filled according to the given mode\n",
    "    horizontal_flip=True, # Randomly flip inputs horizontally\n",
    "    vertical_flip=True, # Randomly flip inputs vertically\n",
    "  )\n",
    "    return datagen\n",
    "# instantiate a data generator\n",
    "c_datagen = crop_datagen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from keras import optimizers\n",
    "\n",
    "dropout_rate = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## as we have less number of images..hence transfer learning will be favourable. Hence picking pre-trained RESNET-50 model and fine-tuning it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_classifier = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "x = base_classifier.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = Dense(1024, activation='relu')(x) \n",
    "x = Dropout(dropout_rate)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(dropout_rate)(x)\n",
    "\n",
    "# a softmax layer for 27 classes\n",
    "predictions = Dense(27, activation='softmax')(x)\n",
    "\n",
    "classifier = classifier(input=base_classifier.input, output=predictions)\n",
    "\n",
    "# freezing layers except top ones\n",
    "for layer in base_classifier.layers:\n",
    "    layer.trainable = False\n",
    "adam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "classifier.compile(optimizer= adam, loss='categorical_crossentropy')\n",
    "\n",
    "\n",
    "# train only the top layers for, say, 30 epochs\n",
    "classifier.fit_generator( c_datagen.flow(cx_train, cy_train), samples_per_epoch=len(X_train) * 5, epochs=30, verbose=2, \n",
    "                    validation_data = (cx_valid,cy_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make all layers trainable\n",
    "for layer in classifier.layers:\n",
    "    layer.trainable=True\n",
    "\n",
    "adam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "classifier.compile(optimizer= adam, loss='categorical_crossentropy')\n",
    "\n",
    "# train the whole net\n",
    "hist2 = classifier.fit_generator( c_datagen.flow(cx_train, cy_train), samples_per_epoch=len(X_train) * 5, epochs=100, verbose=2, \n",
    "                    validation_data = (cx_valid,cy_valid))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting loss curve for classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,3))\n",
    "plt.title('Optimizer : Adam', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.plot(hist2.history['loss'], 'b', label='Training Loss')\n",
    "plt.plot(hist2.history['val_loss'], 'r', label='Validation Loss')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving classifer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "model_json=classifier.to_json()\n",
    "with open(\"logo_classifier.json\",'w')as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "classifier.save_weights(\"logo_classifier.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### final Predictions on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_crop_data = pd.read_table('flickr_logos_27_dataset_query_set_annotation.txt',sep='\\t',names=['filename','logo'], na_values='none',index_col=False)\n",
    "test_crop_data.dropna(inplace=True)\n",
    "test_crop_data.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing images are first cropped using predicted coordinates(bounding box), and then feed into model for final logo classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cx_test = []\n",
    "for i in range(test_crop_data.shape[0]):\n",
    "    cx_test.append( load_crop( 'flickr_logos_27_dataset_images/'+test_crop_data['filename'][i] , y_pred[i][0], y_pred[i][1], y_pred[i][2], y_pred[i][3]))  \n",
    "cx_test = np.array(cx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cy_test = test_crop_data['logo']\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "cy_test  = le.fit_transform(cy_test)\n",
    "\n",
    "from keras.utils import np_utils\n",
    "cy_test = np_utils.to_categorical(cy_test,27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cy_pred = classifier.predict(cx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross-entropy loss score\n",
    "score = log_loss(cy_test, cy_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P.S. : I have not trained the model and hence unable to see the results. But is localizer will perform badly, then it should not be merged or used for classification. In that case, only classifier model will give more accuracy or some other experiments can be done like cropped logos for training and full image (with noise) for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
